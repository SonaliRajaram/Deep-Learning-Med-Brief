{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting rouge\n",
      "  Using cached rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from rouge) (1.16.0)\n",
      "Using cached rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached flatbuffers-25.1.24-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached grpcio-1.70.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached optree-0.14.0-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Using cached tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.1.24-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.70.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached h5py-3.12.1-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "Using cached keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Using cached numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.14.0-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, astunparse, rich, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.2\n",
      "    Uninstalling numpy-2.2.2:\n",
      "      Successfully uninstalled numpy-2.2.2\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-25.1.24 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.12.1 keras-3.8.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.14.0 protobuf-5.29.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0 wheel-0.45.1 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages\\~~mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages\\~~mpy'.\n",
      "  You can safely remove it manually.\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 3.5 MB/s eta 0:00:00\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sonal\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (Convolution Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - loss: 59799.7500\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 60077.1406 \n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 60190.6562\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 58137.8086\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 59403.2539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "ROUGE-1: 0\n",
      "ROUGE-2: 0\n",
      "ROUGE-L: 0\n",
      "ROUGE-Lsum: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('ClinicalData.csv')\n",
    "\n",
    "# Preprocessing\n",
    "data.dropna(inplace=True)  \n",
    "data = data[['Abstract', 'Summarized Abstract']]  \n",
    "\n",
    "# Split data into training (75%) and test (25%)\n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Tokenization and padding for text data\n",
    "tokenizer = Tokenizer(num_words=5000)  \n",
    "tokenizer.fit_on_texts(train_data['Abstract'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
    "max_len = 100  \n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Tokenize and pad the target data (Summarized Abstract)\n",
    "target_tokenizer = Tokenizer(num_words=5000)  \n",
    "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
    "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
    "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
    "max_summary_len = 50  \n",
    "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "\n",
    "# Get the vocabulary size for the output layer\n",
    "vocabulary_size = len(target_tokenizer.word_index) + 1\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=5000, output_dim=1, input_length=max_len),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),  \n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
    "\n",
    "# Generate predicted summaries for the test data\n",
    "predicted_summaries = model.predict(X_test)\n",
    "\n",
    "# Convert sequences back to text\n",
    "predicted_summaries_text = [target_tokenizer.sequences_to_texts([seq])[0] for seq in predicted_summaries]\n",
    "actual_summaries_text = [target_tokenizer.sequences_to_texts([seq])[0] for seq in y_test]\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
    "\n",
    "# Convert sequences back to text for references and hypotheses\n",
    "references = [summary.split() for summary in actual_summaries_text]\n",
    "hypotheses = [summary.split() for summary in predicted_summaries_text]\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "rouge_1 = corpus_bleu(references, hypotheses, weights=(1, 0, 0, 0))\n",
    "rouge_2 = corpus_bleu(references, hypotheses, weights=(0, 1, 0, 0))\n",
    "rouge_l = corpus_bleu(references, hypotheses, weights=(0, 0, 1, 0))\n",
    "rouge_lsum = corpus_bleu(references, hypotheses, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "print(\"ROUGE-1:\", rouge_1)\n",
    "print(\"ROUGE-2:\", rouge_2)\n",
    "print(\"ROUGE-L:\", rouge_l)\n",
    "print(\"ROUGE-Lsum:\", rouge_lsum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - loss: 7.1071\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 7.0780\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 6.9940\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 6.8148\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 6.6053\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 6.4102\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 6.2280\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 6.1416\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 6.1174\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 6.0606\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Example - Actual Summary: are the primary for the of and and models have in understanding these however the of a such as a should factors this scoping review aims to identify and the most factors as well as for of and\n",
      "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
      "\n",
      "Example - Actual Summary: the of clinical is a before more natural language processing models that high accuracy for 1 experience a large of accuracy when to the of this study is to develop methods that clinical the with improved we found improved models only when with in samples improving the score from 0\n",
      "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
      "\n",
      "Example - Actual Summary: the prevention of for patients with is still a great in clinical practice there are studies that to search for strategies to the and life for these patients we aim to the efficacy between different reported treatments by meta analysis most of the studies were high quality with low bias\n",
      "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of the the the the the the the the the the the the the', 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of the the the the the the the the the the the the the the']\n",
      "\n",
      "Example - Actual Summary: large language models problems via text gpt 4 outperformed chatgpt in from free text reports on cancer it also had a lower rate of 1 7 7 4 9 the study included patients underwent cancer follow up between 2021 and\n",
      "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
      "\n",
      "Example - Actual Summary: is a natural found in recent studies have shown that effects against a of cancer types this review a comprehensive overview of the current research and new perspectives on effect it may facilitate the of novel for cancer treatment the need for further clinical and clinical studies to evaluate its\n",
      "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
      "\n",
      "Example - Actual Summary: natural language processing nlp can be used to free text in medical nlp was designed using lists based and decision tree learning it performed better on a more structured format than an unstructured one the study the design of an nlp based approach for evaluation of free text in the\n",
      "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
      "\n",
      "Example - Actual Summary: the main of this were the clinical and the evaluation of conditions including pain and function the of patients with should include a method of and the degree of the value of for was and findings the routine of or testing is not recommended\n",
      "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
      "\n",
      "Example - Actual Summary: study compared in to control was with laser six and six control               23 in the study different and of were found to be significantly different for the different conditions\n",
      "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
      "\n",
      "Example - Actual Summary: use was as no use or use across 1 2 or 4 the incidence rate of use increased significantly with the study that may be an part of a specific of risk future studies should include measures of and to better the variability in back to online back to the\n",
      "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of the the', 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of the the the']\n",
      "\n",
      "Example - Actual Summary: in fast for the               time in an improved understanding of is necessary as these may and risk associated with fast 1 were screened and full text articles were to determine whether they results were reported studies investigating of fast and features age and\n",
      "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of', 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of the the']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('ClinicalData.csv')\n",
    "\n",
    "# Preprocessing\n",
    "data.dropna(inplace=True)  \n",
    "data = data[['Abstract', 'Summarized Abstract']]  \n",
    "\n",
    "# Split data into training (75%) and test (25%)\n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Tokenization and padding for text data\n",
    "tokenizer = Tokenizer(num_words=5000)  \n",
    "tokenizer.fit_on_texts(train_data['Abstract'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
    "max_len = 100  \n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Tokenize and pad the target data (Summarized Abstract)\n",
    "target_tokenizer = Tokenizer(num_words=5000)  \n",
    "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
    "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
    "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
    "max_summary_len = 50  \n",
    "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "\n",
    "# Build a sequence-to-sequence CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_len),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.RepeatVector(max_summary_len),  # Match encoder and decoder lengths\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),  # Added dropout\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(len(target_tokenizer.word_index) + 1, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile the model with 'sparse_categorical_crossentropy' loss\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy')  # Adjusted learning rate\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=16)  \n",
    "\n",
    "# Generate predicted summaries for the test data\n",
    "predicted_summaries = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Implement beam search\n",
    "def beam_search_decoder(data, k):\n",
    "    sequences = [[list(), 1.0]]\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]\n",
    "            for j in range(len(row)):\n",
    "                candidate = [seq + [j], score * -np.log(row[j])]\n",
    "                all_candidates.append(candidate)\n",
    "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
    "        sequences = ordered[:k]\n",
    "    return sequences\n",
    "\n",
    "# Perform beam search for each example in the test data\n",
    "beam_search_results = [beam_search_decoder(sample, k=3) for sample in predicted_summaries]\n",
    "\n",
    "# Convert sequences back to text and print examples\n",
    "for i in range(10):  \n",
    "    actual_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in y_test[i] if word != 0])\n",
    "    predicted_summaries_text = []\n",
    "    for beam_result in beam_search_results[i]:\n",
    "        predicted_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in beam_result[0] if word != 0])\n",
    "        predicted_summaries_text.append(predicted_summary)\n",
    "    print(f\"Example - Actual Summary: {actual_summary}\")\n",
    "    print(f\"Example - Predicted Summaries: {predicted_summaries_text}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN (Recurrent Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 743ms/step - accuracy: 0.0224 - loss: 8.4529\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 762ms/step - accuracy: 0.0843 - loss: 8.8369\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 631ms/step - accuracy: 0.1914 - loss: 6.2584\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683ms/step - accuracy: 0.1961 - loss: 5.7790\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 599ms/step - accuracy: 0.1980 - loss: 5.5767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "ROUGE-1: 0\n",
      "ROUGE-2: 0\n",
      "ROUGE-L: 0\n",
      "ROUGE-Lsum: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('ClinicalData.csv')\n",
    "\n",
    "# Preprocessing\n",
    "data.dropna(inplace=True)  \n",
    "data = data[['Abstract', 'Summarized Abstract']]  \n",
    "\n",
    "# Split data into training (75%) and test (25%)\n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Tokenization and padding for text data\n",
    "tokenizer = Tokenizer(num_words=5000)  \n",
    "tokenizer.fit_on_texts(train_data['Abstract'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
    "max_len = 100  \n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Tokenize and pad the target data (Summarized Abstract)\n",
    "target_tokenizer = Tokenizer(num_words=5000)  \n",
    "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
    "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
    "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
    "max_summary_len = 100  \n",
    "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "\n",
    "# Build and compile the RNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
    "    tf.keras.layers.SimpleRNN(256,  activation='elu',  return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(256,  activation='elu',  return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(256,  activation='elu',  return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(256,  activation='elu',  return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(256,  activation='elu',  return_sequences=True),\n",
    "\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
    "\n",
    "# Generate predicted summaries for the test data\n",
    "predicted_summaries = model.predict(X_test)\n",
    "\n",
    "# Convert sequences back to text\n",
    "predicted_summaries_text = []\n",
    "for seq in predicted_summaries:\n",
    "    text_seq = [str(word) for word in seq]\n",
    "    text_seq = ' '.join(text_seq).strip()\n",
    "    predicted_summaries_text.append(text_seq)\n",
    "\n",
    "actual_summaries_text = []\n",
    "for seq in y_test:\n",
    "    text_seq = [str(word) for word in seq]\n",
    "    text_seq = ' '.join(text_seq).strip()\n",
    "    actual_summaries_text.append(text_seq)\n",
    "\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "rouge_1 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(1, 0, 0, 0))\n",
    "rouge_2 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 1, 0, 0))\n",
    "rouge_l = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 0, 1, 0))\n",
    "rouge_lsum = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "print(\"ROUGE-1:\", rouge_1)\n",
    "print(\"ROUGE-2:\", rouge_2)\n",
    "print(\"ROUGE-L:\", rouge_l)\n",
    "print(\"ROUGE-Lsum:\", rouge_lsum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 556ms/step - accuracy: 0.0230 - loss: 8.4212\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 547ms/step - accuracy: 0.1891 - loss: 9.0500\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 546ms/step - accuracy: 0.0599 - loss: 6.4994\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 546ms/step - accuracy: 0.1242 - loss: 5.7341\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 568ms/step - accuracy: 0.1951 - loss: 5.4709\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Local\\Temp\\ipykernel_20964\\320236236.py:66: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  candidate = [seq + [j], score * -np.log(row[j])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - Actual Summary: are the primary for the of and and models have in understanding these however the of a such as a should factors this scoping review aims to identify and the most factors as well as for of and\n",
      "Example - Predicted Summaries: ['and of to for of systems in to of', 'and of to for of systems in to of the', 'and of to for of systems in to of of']\n",
      "\n",
      "Example - Actual Summary: the of clinical is a before more natural language processing models that high accuracy for 1 experience a large of accuracy when to the of this study is to develop methods that clinical the with improved we found improved models only when with in samples improving the score from 0 to 0\n",
      "Example - Predicted Summaries: ['', 'in', 'with']\n",
      "\n",
      "Example - Actual Summary: the prevention of for patients with is still a great in clinical practice there are studies that to search for strategies to the and life for these patients we aim to the efficacy between different reported treatments by meta analysis most of the studies were high quality with low bias and were when the of life\n",
      "Example - Predicted Summaries: ['in of in', 'in of in the', 'in of in of']\n",
      "\n",
      "Example - Actual Summary: large language models problems via text gpt 4 outperformed chatgpt in from free text reports on cancer it also had a lower rate of 1 7 7 4 9 the study included patients underwent cancer follow up between 2021 and\n",
      "Example - Predicted Summaries: ['of and of', 'and of and of', 'and of and of']\n",
      "\n",
      "Example - Actual Summary: is a natural found in recent studies have shown that effects against a of cancer types this review a comprehensive overview of the current research and new perspectives on effect it may facilitate the of novel for cancer treatment the need for further clinical and clinical studies to evaluate its safety and efficacy further the authors conclude the study was published in the journal of cancer research\n",
      "Example - Predicted Summaries: ['', 'the', 'of']\n",
      "\n",
      "Example - Actual Summary: natural language processing nlp can be used to free text in medical nlp was designed using lists based and decision tree learning it performed better on a more structured format than an unstructured one the study the design of an nlp based approach for evaluation of free text in the it a for further more nlp approaches models\n",
      "Example - Predicted Summaries: ['', 'and', 'by']\n",
      "\n",
      "Example - Actual Summary: the main of this were the clinical and the evaluation of conditions including pain and function the of patients with should include a method of and the degree of the value of for was and findings the routine of or testing is not recommended\n",
      "Example - Predicted Summaries: ['', 'the', 'of']\n",
      "\n",
      "Example - Actual Summary: study compared in to control was with laser six and six control               23 in the study different and of were found to be significantly different for the different conditions\n",
      "Example - Predicted Summaries: ['', 'and', 'of']\n",
      "\n",
      "Example - Actual Summary: use was as no use or use across 1 2 or 4 the incidence rate of use increased significantly with the study that may be an part of a specific of risk future studies should include measures of and to better the variability in back to online back to the from\n",
      "Example - Predicted Summaries: ['in', 'for in', 'in in']\n",
      "\n",
      "Example - Actual Summary: in fast for the               time in an improved understanding of is necessary as these may and risk associated with fast 1 were screened and full text articles were to determine whether they results were reported studies investigating of fast and features age and characteristics\n",
      "Example - Predicted Summaries: ['in of and to of and and', 'in of and to of and and the', 'in of and to of and and of']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RNN print actual summary and predicted summary\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('ClinicalData.csv')\n",
    "\n",
    "# Preprocessing\n",
    "data.dropna(inplace=True)  \n",
    "data = data[['Abstract', 'Summarized Abstract']]  \n",
    "\n",
    "# Split data into training (75%) and test (25%)\n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Tokenization and padding for text data\n",
    "tokenizer = Tokenizer(num_words=5000)  \n",
    "tokenizer.fit_on_texts(train_data['Abstract'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
    "max_len = 100  \n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Tokenize and pad the target data (Summarized Abstract)\n",
    "target_tokenizer = Tokenizer(num_words=5000)  \n",
    "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
    "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
    "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
    "max_summary_len = 100  \n",
    "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "\n",
    "# Build and compile the RNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
    "    tf.keras.layers.SimpleRNN(256, activation='elu', return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(256, activation='elu', return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(256, activation='elu', return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(256, activation='elu', return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(256, activation='elu', return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
    "\n",
    "# Generate predicted summaries for the test data\n",
    "predicted_summaries = model.predict(X_test)\n",
    "\n",
    "# Implement beam search\n",
    "def beam_search_decoder(data, k):\n",
    "    sequences = [[list(), 1.0]]\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]\n",
    "            for j in range(len(row)):\n",
    "                candidate = [seq + [j], score * -np.log(row[j])]\n",
    "                all_candidates.append(candidate)\n",
    "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
    "        sequences = ordered[:k]\n",
    "    return sequences\n",
    "\n",
    "# Perform beam search for each example in the test data\n",
    "beam_search_results = [beam_search_decoder(sample, k=3) for sample in predicted_summaries]\n",
    "\n",
    "# Convert sequences back to text and print examples\n",
    "for i in range(10):  \n",
    "    actual_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in y_test[i] if word != 0])\n",
    "    predicted_summaries_text = []\n",
    "    for beam_result in beam_search_results[i]:\n",
    "        predicted_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in beam_result[0] if word != 0])\n",
    "        predicted_summaries_text.append(predicted_summary)\n",
    "    print(f\"Example - Actual Summary: {actual_summary}\")\n",
    "    print(f\"Example - Predicted Summaries: {predicted_summaries_text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM (Long short-term memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 678ms/step - accuracy: 0.0133 - loss: 8.5163\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 615ms/step - accuracy: 0.1857 - loss: 8.5045\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 563ms/step - accuracy: 0.1852 - loss: 8.4692\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 672ms/step - accuracy: 0.1896 - loss: 7.5973\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 629ms/step - accuracy: 0.1884 - loss: 8.4098\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000241E725C040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "ROUGE-1: 0\n",
      "ROUGE-2: 0\n",
      "ROUGE-L: 0\n",
      "ROUGE-Lsum: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('ClinicalData.csv')\n",
    "\n",
    "# Preprocessing\n",
    "data.dropna(inplace=True)  \n",
    "data = data[['Abstract', 'Summarized Abstract']]  \n",
    "\n",
    "# Split data into training (75%) and test (25%)\n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Tokenization and padding for text data\n",
    "tokenizer = Tokenizer(num_words=5000)  \n",
    "tokenizer.fit_on_texts(train_data['Abstract'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
    "max_len = 100  \n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Tokenize and pad the target data (Summarized Abstract)\n",
    "target_tokenizer = Tokenizer(num_words=5000)  \n",
    "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
    "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
    "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
    "max_summary_len = 100  \n",
    "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "\n",
    "# Build and compile the LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
    "    tf.keras.layers.LSTM(256, return_sequences=True, activation='relu'),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
    "\n",
    "# Generate predicted summaries for the test data\n",
    "predicted_summaries = model.predict(X_test)\n",
    "\n",
    "# Convert sequences back to text\n",
    "predicted_summaries_text = []\n",
    "for seq in predicted_summaries:\n",
    "    text_seq = [str(word) for word in seq]\n",
    "    text_seq = ' '.join(text_seq).strip()\n",
    "    predicted_summaries_text.append(text_seq)\n",
    "\n",
    "actual_summaries_text = []\n",
    "for seq in y_test:\n",
    "    text_seq = [str(word) for word in seq]\n",
    "    text_seq = ' '.join(text_seq).strip()\n",
    "    actual_summaries_text.append(text_seq)\n",
    "\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "rouge_1 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(1, 0, 0, 0))\n",
    "rouge_2 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 1, 0, 0))\n",
    "rouge_l = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 0, 1, 0))\n",
    "rouge_lsum = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "print(\"ROUGE-1:\", rouge_1)\n",
    "print(\"ROUGE-2:\", rouge_2)\n",
    "print(\"ROUGE-L:\", rouge_l)\n",
    "print(\"ROUGE-Lsum:\", rouge_lsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 638ms/step - accuracy: 0.0680 - loss: 8.5152\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 579ms/step - accuracy: 0.1814 - loss: 8.5026\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 616ms/step - accuracy: 0.1822 - loss: 8.4475\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 580ms/step - accuracy: 0.1943 - loss: 7.6132\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 615ms/step - accuracy: 0.1547 - loss: 8.1312\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000241D3C18AE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Local\\Temp\\ipykernel_20964\\2343647717.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  candidate = [seq + [j], score * -np.log(row[j])]\n",
      "C:\\Users\\sonal\\AppData\\Local\\Temp\\ipykernel_20964\\2343647717.py:62: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  candidate = [seq + [j], score * -np.log(row[j])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - Actual Summary: are the primary for the of and and models have in understanding these however the of a such as a should factors this scoping review aims to identify and the most factors as well as for of and\n",
      "Example - Predicted Summaries: ['and', 'and the', 'and of']\n",
      "\n",
      "Example - Actual Summary: the of clinical is a before more natural language processing models that high accuracy for 1 experience a large of accuracy when to the of this study is to develop methods that clinical the with improved we found improved models only when with in samples improving the score from 0 to 0\n",
      "Example - Predicted Summaries: ['the', 'the the', 'the of']\n",
      "\n",
      "Example - Actual Summary: the prevention of for patients with is still a great in clinical practice there are studies that to search for strategies to the and life for these patients we aim to the efficacy between different reported treatments by meta analysis most of the studies were high quality with low bias and were when the of life\n",
      "Example - Predicted Summaries: ['', 'the', 'of']\n",
      "\n",
      "Example - Actual Summary: large language models problems via text gpt 4 outperformed chatgpt in from free text reports on cancer it also had a lower rate of 1 7 7 4 9 the study included patients underwent cancer follow up between 2021 and\n",
      "Example - Predicted Summaries: ['a', 'a the', 'a of']\n",
      "\n",
      "Example - Actual Summary: is a natural found in recent studies have shown that effects against a of cancer types this review a comprehensive overview of the current research and new perspectives on effect it may facilitate the of novel for cancer treatment the need for further clinical and clinical studies to evaluate its safety and efficacy further the authors conclude the study was published in the journal of cancer research\n",
      "Example - Predicted Summaries: ['a', 'a the', 'a of']\n",
      "\n",
      "Example - Actual Summary: natural language processing nlp can be used to free text in medical nlp was designed using lists based and decision tree learning it performed better on a more structured format than an unstructured one the study the design of an nlp based approach for evaluation of free text in the it a for further more nlp approaches models\n",
      "Example - Predicted Summaries: ['a', 'a the', 'a of']\n",
      "\n",
      "Example - Actual Summary: the main of this were the clinical and the evaluation of conditions including pain and function the of patients with should include a method of and the degree of the value of for was and findings the routine of or testing is not recommended\n",
      "Example - Predicted Summaries: ['and', 'and the', 'and of']\n",
      "\n",
      "Example - Actual Summary: study compared in to control was with laser six and six control               23 in the study different and of were found to be significantly different for the different conditions\n",
      "Example - Predicted Summaries: ['and', 'and the', 'and of']\n",
      "\n",
      "Example - Actual Summary: use was as no use or use across 1 2 or 4 the incidence rate of use increased significantly with the study that may be an part of a specific of risk future studies should include measures of and to better the variability in back to online back to the from\n",
      "Example - Predicted Summaries: ['of', 'of the', 'of of']\n",
      "\n",
      "Example - Actual Summary: in fast for the               time in an improved understanding of is necessary as these may and risk associated with fast 1 were screened and full text articles were to determine whether they results were reported studies investigating of fast and features age and characteristics\n",
      "Example - Predicted Summaries: ['a', 'a the', 'a of']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LSTM - PRINTING ACTUAL AND PREDICTED SUMMARIES TEXT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('ClinicalData.csv')\n",
    "\n",
    "# Preprocessing\n",
    "data.dropna(inplace=True)  \n",
    "data = data[['Abstract', 'Summarized Abstract']]  \n",
    "\n",
    "# Split data into training (75%) and test (25%)\n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Tokenization and padding for text data\n",
    "tokenizer = Tokenizer(num_words=5000)  \n",
    "tokenizer.fit_on_texts(train_data['Abstract'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
    "max_len = 100  \n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Tokenize and pad the target data (Summarized Abstract)\n",
    "target_tokenizer = Tokenizer(num_words=5000) \n",
    "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
    "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
    "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
    "max_summary_len = 100  \n",
    "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "\n",
    "# Build and compile the LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
    "    tf.keras.layers.LSTM(256, return_sequences=True, activation='relu'),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
    "\n",
    "# Generate predicted summaries for the test data\n",
    "predicted_summaries = model.predict(X_test)\n",
    "\n",
    "# Implement beam search\n",
    "def beam_search_decoder(data, k):\n",
    "    sequences = [[list(), 1.0]]\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]\n",
    "            for j in range(len(row)):\n",
    "                candidate = [seq + [j], score * -np.log(row[j])]\n",
    "                all_candidates.append(candidate)\n",
    "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
    "        sequences = ordered[:k]\n",
    "    return sequences\n",
    "\n",
    "# Perform beam search for each example in the test data\n",
    "beam_search_results = [beam_search_decoder(sample, k=3) for sample in predicted_summaries]\n",
    "\n",
    "# Convert sequences back to text and print examples\n",
    "for i in range(10):  \n",
    "    actual_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in y_test[i] if word != 0])\n",
    "    predicted_summaries_text = []\n",
    "    for beam_result in beam_search_results[i]:\n",
    "        predicted_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in beam_result[0] if word != 0])\n",
    "        predicted_summaries_text.append(predicted_summary)\n",
    "    print(f\"Example - Actual Summary: {actual_summary}\")\n",
    "    print(f\"Example - Predicted Summaries: {predicted_summaries_text}\\n\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 404ms/step - accuracy: 0.0199 - loss: 8.5164\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465ms/step - accuracy: 0.0464 - loss: 8.5055\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413ms/step - accuracy: 0.0469 - loss: 8.4322\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - accuracy: 0.0438 - loss: 8.9490\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - accuracy: 0.0495 - loss: 8.2497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "ROUGE-1: 0\n",
      "ROUGE-2: 0\n",
      "ROUGE-L: 0\n",
      "ROUGE-Lsum: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('ClinicalData.csv')\n",
    "\n",
    "# Preprocessing\n",
    "data.dropna(inplace=True)  \n",
    "data = data[['Abstract', 'Summarized Abstract']]  \n",
    "\n",
    "# Split data into training (75%) and test (25%)\n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Tokenization and padding for text data\n",
    "tokenizer = Tokenizer(num_words=5000)  \n",
    "tokenizer.fit_on_texts(train_data['Abstract'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
    "max_len = 100  \n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Tokenize and pad the target data (Summarized Abstract)\n",
    "target_tokenizer = Tokenizer(num_words=5000)  \n",
    "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
    "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
    "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
    "max_summary_len = 48  \n",
    "\n",
    "# Padding or truncating the input sequences\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Padding or truncating the target sequences\n",
    "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "# Build and compile the CNN-RNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),  \n",
    "    tf.keras.layers.MaxPooling1D(2),\n",
    "    tf.keras.layers.LSTM(256, activation='relu', return_sequences=True),\n",
    "    tf.keras.layers.LSTM(256, activation='relu', return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
    "\n",
    "# Generate predicted summaries for the test data\n",
    "predicted_summaries = model.predict(X_test)\n",
    "\n",
    "# Convert sequences back to text\n",
    "predicted_summaries_text = []\n",
    "for seq in predicted_summaries:\n",
    "    text_seq = [str(word) for word in seq]\n",
    "    text_seq = ' '.join(text_seq).strip()\n",
    "    predicted_summaries_text.append(text_seq)\n",
    "\n",
    "actual_summaries_text = []\n",
    "for seq in y_test:\n",
    "    text_seq = [str(word) for word in seq]\n",
    "    text_seq = ' '.join(text_seq).strip()\n",
    "    actual_summaries_text.append(text_seq)\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "rouge_1 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(1, 0, 0, 0))\n",
    "rouge_2 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 1, 0, 0))\n",
    "rouge_l = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 0, 1, 0))\n",
    "rouge_lsum = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "print(\"ROUGE-1:\", rouge_1)\n",
    "print(\"ROUGE-2:\", rouge_2)\n",
    "print(\"ROUGE-L:\", rouge_l)\n",
    "print(\"ROUGE-Lsum:\", rouge_lsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 413ms/step - accuracy: 0.0026 - loss: 8.5166 \n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - accuracy: 0.0480 - loss: 8.5070\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 401ms/step - accuracy: 0.0487 - loss: 8.4574\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - accuracy: 0.0463 - loss: 8.2681\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409ms/step - accuracy: 0.0481 - loss: 8.3496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Local\\Temp\\ipykernel_20964\\3102310156.py:72: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  candidate = [seq + [j], score * -np.log(row[j])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - Actual Summary: are the primary for the of and and models have in understanding these however the of a such as a should factors this scoping review aims to identify and the most factors as well as for of and\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: the of clinical is a before more natural language processing models that high accuracy for 1 experience a large of accuracy when to the of this study is to develop methods that clinical the with improved we found improved models only when with in samples improving the score\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: the prevention of for patients with is still a great in clinical practice there are studies that to search for strategies to the and life for these patients we aim to the efficacy between different reported treatments by meta analysis most of the studies were high quality with\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: large language models problems via text gpt 4 outperformed chatgpt in from free text reports on cancer it also had a lower rate of 1 7 7 4 9 the study included patients underwent cancer follow up between 2021 and\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: is a natural found in recent studies have shown that effects against a of cancer types this review a comprehensive overview of the current research and new perspectives on effect it may facilitate the of novel for cancer treatment the need for further clinical and clinical studies to\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: natural language processing nlp can be used to free text in medical nlp was designed using lists based and decision tree learning it performed better on a more structured format than an unstructured one the study the design of an nlp based approach for evaluation of free text\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: the main of this were the clinical and the evaluation of conditions including pain and function the of patients with should include a method of and the degree of the value of for was and findings the routine of or testing is not recommended\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: study compared in to control was with laser six and six control               23 in the study different and of were found to be significantly different for the different conditions\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: use was as no use or use across 1 2 or 4 the incidence rate of use increased significantly with the study that may be an part of a specific of risk future studies should include measures of and to better the variability in back to online back\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: in fast for the               time in an improved understanding of is necessary as these may and risk associated with fast 1 were screened and full text articles were to determine whether they results were reported studies investigating of fast and features\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cnn + rnn - PRINTING ACTUAL AND PREDICTED SUMMARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('ClinicalData.csv')\n",
    "\n",
    "# Preprocessing\n",
    "data.dropna(inplace=True)  \n",
    "data = data[['Abstract', 'Summarized Abstract']]  \n",
    "\n",
    "# Split data into training (75%) and test (25%)\n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Tokenization and padding for text data\n",
    "tokenizer = Tokenizer(num_words=5000)  \n",
    "tokenizer.fit_on_texts(train_data['Abstract'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
    "max_len = 100  \n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Tokenize and pad the target data (Summarized Abstract)\n",
    "target_tokenizer = Tokenizer(num_words=5000)  \n",
    "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
    "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
    "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
    "max_summary_len = 48  \n",
    "\n",
    "# Padding or truncating the input sequences\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Padding or truncating the target sequences\n",
    "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "# Build and compile the CNN-RNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),  \n",
    "    tf.keras.layers.MaxPooling1D(2),\n",
    "    tf.keras.layers.LSTM(256, activation='relu', return_sequences=True),\n",
    "    tf.keras.layers.LSTM(256, activation='relu', return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
    "\n",
    "# Generate predicted summaries for the test data\n",
    "predicted_summaries = model.predict(X_test)\n",
    "\n",
    "# Implement beam search\n",
    "def beam_search_decoder(data, k):\n",
    "    sequences = [[list(), 1.0]]\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]\n",
    "            for j in range(len(row)):\n",
    "                candidate = [seq + [j], score * -np.log(row[j])]\n",
    "                all_candidates.append(candidate)\n",
    "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
    "        sequences = ordered[:k]\n",
    "    return sequences\n",
    "\n",
    "# Perform beam search for each example in the test data\n",
    "beam_search_results = [beam_search_decoder(sample, k=3) for sample in predicted_summaries]\n",
    "\n",
    "# Convert sequences back to text and print examples\n",
    "for i in range(10):  \n",
    "    actual_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in y_test[i] if word != 0])\n",
    "    predicted_summaries_text = []\n",
    "    for beam_result in beam_search_results[i]:\n",
    "        predicted_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in beam_result[0] if word != 0])\n",
    "        predicted_summaries_text.append(predicted_summary)\n",
    "    print(f\"Example - Actual Summary: {actual_summary}\")\n",
    "    print(f\"Example - Predicted Summaries: {predicted_summaries_text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# biLSTM (Bidirectional LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 481ms/step - accuracy: 0.0026 - loss: 8.5161 \n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 496ms/step - accuracy: 0.0518 - loss: 8.4960\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 611ms/step - accuracy: 0.0490 - loss: 8.4195\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 480ms/step - accuracy: 0.0485 - loss: 8.6334\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 460ms/step - accuracy: 0.0448 - loss: 7.9795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "ROUGE-1: 0\n",
      "ROUGE-2: 0\n",
      "ROUGE-L: 0\n",
      "ROUGE-Lsum: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('ClinicalData.csv')\n",
    "\n",
    "# Preprocessing\n",
    "data.dropna(inplace=True) \n",
    "data = data[['Abstract', 'Summarized Abstract']]  \n",
    "\n",
    "# Split data into training (75%) and test (25%)\n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Tokenization and padding for text data\n",
    "tokenizer = Tokenizer(num_words=5000)  \n",
    "tokenizer.fit_on_texts(train_data['Abstract'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
    "max_len = 100  \n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Tokenize and pad the target data (Summarized Abstract)\n",
    "target_tokenizer = Tokenizer(num_words=5000)  \n",
    "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
    "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
    "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
    "max_summary_len = 48  \n",
    "\n",
    "# Padding or truncating the input sequences\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Padding or truncating the target sequences\n",
    "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "\n",
    "# Build and compile the BiLSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),  \n",
    "    tf.keras.layers.MaxPooling1D(2),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, activation='relu', return_sequences=True)),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
    "\n",
    "# Generate predicted summaries for the test data\n",
    "predicted_summaries = model.predict(X_test)\n",
    "\n",
    "# Convert sequences back to text\n",
    "predicted_summaries_text = []\n",
    "for seq in predicted_summaries:\n",
    "    text_seq = [str(word) for word in seq]\n",
    "    text_seq = ' '.join(text_seq).strip()\n",
    "    predicted_summaries_text.append(text_seq)\n",
    "\n",
    "actual_summaries_text = []\n",
    "for seq in y_test:\n",
    "    text_seq = [str(word) for word in seq]\n",
    "    text_seq = ' '.join(text_seq).strip()\n",
    "    actual_summaries_text.append(text_seq)\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "rouge_1 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(1, 0, 0, 0))\n",
    "rouge_2 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 1, 0, 0))\n",
    "rouge_l = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 0, 1, 0))\n",
    "rouge_lsum = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "print(\"ROUGE-1:\", rouge_1)\n",
    "print(\"ROUGE-2:\", rouge_2)\n",
    "print(\"ROUGE-L:\", rouge_l)\n",
    "print(\"ROUGE-Lsum:\", rouge_lsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 444ms/step - accuracy: 0.0182 - loss: 8.5152\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - accuracy: 0.0474 - loss: 8.4898\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 494ms/step - accuracy: 0.0510 - loss: 8.3576\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step - accuracy: 0.0477 - loss: 9.1156\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 451ms/step - accuracy: 0.0506 - loss: 8.1282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Local\\Temp\\ipykernel_20964\\1869521072.py:69: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  candidate = [seq + [j], score * -np.log(row[j])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - Actual Summary: are the primary for the of and and models have in understanding these however the of a such as a should factors this scoping review aims to identify and the most factors as well as for of and\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: the of clinical is a before more natural language processing models that high accuracy for 1 experience a large of accuracy when to the of this study is to develop methods that clinical the with improved we found improved models only when with in samples improving the score\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: the prevention of for patients with is still a great in clinical practice there are studies that to search for strategies to the and life for these patients we aim to the efficacy between different reported treatments by meta analysis most of the studies were high quality with\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: large language models problems via text gpt 4 outperformed chatgpt in from free text reports on cancer it also had a lower rate of 1 7 7 4 9 the study included patients underwent cancer follow up between 2021 and\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: is a natural found in recent studies have shown that effects against a of cancer types this review a comprehensive overview of the current research and new perspectives on effect it may facilitate the of novel for cancer treatment the need for further clinical and clinical studies to\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: natural language processing nlp can be used to free text in medical nlp was designed using lists based and decision tree learning it performed better on a more structured format than an unstructured one the study the design of an nlp based approach for evaluation of free text\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: the main of this were the clinical and the evaluation of conditions including pain and function the of patients with should include a method of and the degree of the value of for was and findings the routine of or testing is not recommended\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: study compared in to control was with laser six and six control               23 in the study different and of were found to be significantly different for the different conditions\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: use was as no use or use across 1 2 or 4 the incidence rate of use increased significantly with the study that may be an part of a specific of risk future studies should include measures of and to better the variability in back to online back\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n",
      "Example - Actual Summary: in fast for the               time in an improved understanding of is necessary as these may and risk associated with fast 1 were screened and full text articles were to determine whether they results were reported studies investigating of fast and features\n",
      "Example - Predicted Summaries: ['of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#bilstm - PRINTING ACTUAL AND PREDICTED SUMMARIES TEXT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('ClinicalData.csv')\n",
    "\n",
    "# Preprocessing\n",
    "data.dropna(inplace=True)  \n",
    "data = data[['Abstract', 'Summarized Abstract']]  \n",
    "\n",
    "# Split data into training (75%) and test (25%)\n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Tokenization and padding for text data\n",
    "tokenizer = Tokenizer(num_words=5000)  \n",
    "tokenizer.fit_on_texts(train_data['Abstract'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
    "max_len = 100  \n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Tokenize and pad the target data (Summarized Abstract)\n",
    "target_tokenizer = Tokenizer(num_words=5000)  \n",
    "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
    "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
    "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
    "max_summary_len = 48  \n",
    "\n",
    "# Padding or truncating the input sequences\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Padding or truncating the target sequences\n",
    "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "\n",
    "# Build and compile the BiLSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),  # You can adjust the filter size and number of filters\n",
    "    tf.keras.layers.MaxPooling1D(2),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, activation='relu', return_sequences=True)),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
    "\n",
    "predicted_summaries = model.predict(X_test)\n",
    "\n",
    "# Implement beam search\n",
    "def beam_search_decoder(data, k):\n",
    "    sequences = [[list(), 1.0]]\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]\n",
    "            for j in range(len(row)):\n",
    "                candidate = [seq + [j], score * -np.log(row[j])]\n",
    "                all_candidates.append(candidate)\n",
    "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
    "        sequences = ordered[:k]\n",
    "    return sequences\n",
    "\n",
    "# Perform beam search for each example in the test data\n",
    "beam_search_results = [beam_search_decoder(sample, k=3) for sample in predicted_summaries]\n",
    "\n",
    "# Convert sequences back to text and print examples\n",
    "for i in range(10):  \n",
    "    actual_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in y_test[i] if word != 0])\n",
    "    predicted_summaries_text = []\n",
    "    for beam_result in beam_search_results[i]:\n",
    "        predicted_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in beam_result[0] if word != 0])\n",
    "        predicted_summaries_text.append(predicted_summary)\n",
    "    print(f\"Example - Actual Summary: {actual_summary}\")\n",
    "    print(f\"Example - Predicted Summaries: {predicted_summaries_text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 330ms/step - accuracy: 0.0020 - loss: 8.5162 \n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - accuracy: 0.0488 - loss: 8.5017\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 283ms/step - accuracy: 0.0446 - loss: 8.4331\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step - accuracy: 0.0487 - loss: 9.4214\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280ms/step - accuracy: 0.0348 - loss: 8.0365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "ROUGE-1: 0\n",
      "ROUGE-2: 0\n",
      "ROUGE-L: 0\n",
      "ROUGE-Lsum: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('ClinicalData.csv')\n",
    "\n",
    "# Preprocessing\n",
    "data.dropna(inplace=True)  \n",
    "data = data[['Abstract', 'Summarized Abstract']]  \n",
    "\n",
    "# Split data into training (75%) and test (25%)\n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Tokenization and padding for text data\n",
    "tokenizer = Tokenizer(num_words=5000)  \n",
    "tokenizer.fit_on_texts(train_data['Abstract'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
    "max_len = 100  \n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Tokenize and pad the target data (Summarized Abstract)\n",
    "target_tokenizer = Tokenizer(num_words=5000)  \n",
    "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
    "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
    "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
    "max_summary_len = 48  \n",
    "\n",
    "# Padding or truncating the input sequences\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Padding or truncating the target sequences\n",
    "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "\n",
    "# Build and compile the CNN + LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),  \n",
    "    tf.keras.layers.MaxPooling1D(2),\n",
    "    tf.keras.layers.LSTM(256, activation='relu', return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
    "\n",
    "# Generate predicted summaries for the test data\n",
    "predicted_summaries = model.predict(X_test)\n",
    "\n",
    "# Convert sequences back to text\n",
    "predicted_summaries_text = []\n",
    "for seq in predicted_summaries:\n",
    "    text_seq = [str(word) for word in seq]\n",
    "    text_seq = ' '.join(text_seq).strip()\n",
    "    predicted_summaries_text.append(text_seq)\n",
    "\n",
    "actual_summaries_text = []\n",
    "for seq in y_test:\n",
    "    text_seq = [str(word) for word in seq]\n",
    "    text_seq = ' '.join(text_seq).strip()\n",
    "    actual_summaries_text.append(text_seq)\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "rouge_1 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(1, 0, 0, 0))\n",
    "rouge_2 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 1, 0, 0))\n",
    "rouge_l = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 0, 1, 0))\n",
    "rouge_lsum = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "print(\"ROUGE-1:\", rouge_1)\n",
    "print(\"ROUGE-2:\", rouge_2)\n",
    "print(\"ROUGE-L:\", rouge_l)\n",
    "print(\"ROUGE-Lsum:\", rouge_lsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 274ms/step - accuracy: 0.0017 - loss: 8.5164 \n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - accuracy: 0.0468 - loss: 8.5029\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275ms/step - accuracy: 0.0444 - loss: 8.4440\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - accuracy: 0.0473 - loss: 8.5308\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274ms/step - accuracy: 0.0425 - loss: 8.3054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonal\\AppData\\Local\\Temp\\ipykernel_20964\\2441848445.py:71: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  candidate = [seq + [j], score * -np.log(row[j])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - Actual Summary: are the primary for the of and and models have in understanding these however the of a such as a should factors this scoping review aims to identify and the most factors as well as for of and\n",
      "Example - Predicted Summaries: ['studies studies studies studies studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'studies studies studies studies studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'studies studies studies studies studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of']\n",
      "\n",
      "Example - Actual Summary: the of clinical is a before more natural language processing models that high accuracy for 1 experience a large of accuracy when to the of this study is to develop methods that clinical the with improved we found improved models only when with in samples improving the score\n",
      "Example - Predicted Summaries: ['a studies studies studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'a studies studies studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'a studies studies studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of']\n",
      "\n",
      "Example - Actual Summary: the prevention of for patients with is still a great in clinical practice there are studies that to search for strategies to the and life for these patients we aim to the efficacy between different reported treatments by meta analysis most of the studies were high quality with\n",
      "Example - Predicted Summaries: ['studies studies studies studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'studies studies studies studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'studies studies studies studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of']\n",
      "\n",
      "Example - Actual Summary: large language models problems via text gpt 4 outperformed chatgpt in from free text reports on cancer it also had a lower rate of 1 7 7 4 9 the study included patients underwent cancer follow up between 2021 and\n",
      "Example - Predicted Summaries: ['studies studies studies studies studies studies studies studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'studies studies studies studies studies studies studies studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'studies studies studies studies studies studies studies studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of']\n",
      "\n",
      "Example - Actual Summary: is a natural found in recent studies have shown that effects against a of cancer types this review a comprehensive overview of the current research and new perspectives on effect it may facilitate the of novel for cancer treatment the need for further clinical and clinical studies to\n",
      "Example - Predicted Summaries: ['a a studies studies a a a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'a a studies studies a a a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'a a studies studies a a a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of']\n",
      "\n",
      "Example - Actual Summary: natural language processing nlp can be used to free text in medical nlp was designed using lists based and decision tree learning it performed better on a more structured format than an unstructured one the study the design of an nlp based approach for evaluation of free text\n",
      "Example - Predicted Summaries: ['a a a a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'a a a a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'a a a a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of']\n",
      "\n",
      "Example - Actual Summary: the main of this were the clinical and the evaluation of conditions including pain and function the of patients with should include a method of and the degree of the value of for was and findings the routine of or testing is not recommended\n",
      "Example - Predicted Summaries: ['a a studies a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'a a studies a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'a a studies a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of']\n",
      "\n",
      "Example - Actual Summary: study compared in to control was with laser six and six control               23 in the study different and of were found to be significantly different for the different conditions\n",
      "Example - Predicted Summaries: ['a a a a studies studies the studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'a a a a studies studies the studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'a a a a studies studies the studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of']\n",
      "\n",
      "Example - Actual Summary: use was as no use or use across 1 2 or 4 the incidence rate of use increased significantly with the study that may be an part of a specific of risk future studies should include measures of and to better the variability in back to online back\n",
      "Example - Predicted Summaries: ['a a a a a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'a a a a a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'a a a a a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of']\n",
      "\n",
      "Example - Actual Summary: in fast for the               time in an improved understanding of is necessary as these may and risk associated with fast 1 were screened and full text articles were to determine whether they results were reported studies investigating of fast and features\n",
      "Example - Predicted Summaries: ['a a a studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'a a a studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'a a a studies studies the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cnn+lstm PRINTING ACTUAL AND PREDICTED SUMMARIES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('ClinicalData.csv')\n",
    "\n",
    "# Preprocessing\n",
    "data.dropna(inplace=True)  \n",
    "data = data[['Abstract', 'Summarized Abstract']]  \n",
    "\n",
    "# Split data into training (75%) and test (25%)\n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Tokenization and padding for text data\n",
    "tokenizer = Tokenizer(num_words=5000)  \n",
    "tokenizer.fit_on_texts(train_data['Abstract'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
    "max_len = 100  \n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Tokenize and pad the target data (Summarized Abstract)\n",
    "target_tokenizer = Tokenizer(num_words=5000)  \n",
    "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
    "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
    "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
    "max_summary_len = 48  \n",
    "\n",
    "# Padding or truncating the input sequences\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Padding or truncating the target sequences\n",
    "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
    "\n",
    "# Build and compile the CNN + LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),  \n",
    "    tf.keras.layers.MaxPooling1D(2),\n",
    "    tf.keras.layers.LSTM(256, activation='relu', return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
    "\n",
    "# Generate predicted summaries for the test data\n",
    "predicted_summaries = model.predict(X_test)\n",
    "\n",
    "# Implement beam search\n",
    "def beam_search_decoder(data, k):\n",
    "    sequences = [[list(), 1.0]]\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]\n",
    "            for j in range(len(row)):\n",
    "                candidate = [seq + [j], score * -np.log(row[j])]\n",
    "                all_candidates.append(candidate)\n",
    "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
    "        sequences = ordered[:k]\n",
    "    return sequences\n",
    "\n",
    "# Perform beam search for each example in the test data\n",
    "beam_search_results = [beam_search_decoder(sample, k=3) for sample in predicted_summaries]\n",
    "\n",
    "# Convert sequences back to text and print examples\n",
    "for i in range(10):  \n",
    "    actual_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in y_test[i] if word != 0])\n",
    "    predicted_summaries_text = []\n",
    "    for beam_result in beam_search_results[i]:\n",
    "        predicted_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in beam_result[0] if word != 0])\n",
    "        predicted_summaries_text.append(predicted_summary)\n",
    "    print(f\"Example - Actual Summary: {actual_summary}\")\n",
    "    print(f\"Example - Predicted Summaries: {predicted_summaries_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
